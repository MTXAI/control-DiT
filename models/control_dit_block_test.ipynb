{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-31T10:10:05.559775Z",
     "start_time": "2024-05-31T10:10:03.986886Z"
    }
   },
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from accelerate import Accelerator\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder, ImageNet\n",
    "\n",
    "from utils.dataset import CustomDataset\n",
    "from utils.image_tools import ImageTools\n",
    "\n",
    "# CUDA = True if torch.cuda.is_available() else False\n",
    "CUDA = False\n",
    "Tensor = torch.cuda.FloatTensor if CUDA else torch.FloatTensor\n",
    "Device = \"cuda\" if CUDA else \"cpu\"\n",
    "imgTools = ImageTools()\n",
    "\n",
    "root = \"../datasets/imagenet2012_processed_train\"\n",
    "batch_size = 1\n",
    "num_workers = 0\n",
    "image_size = 256\n",
    "\n",
    "features_dir = os.path.join(root, f'imagenet{image_size}_features')\n",
    "labels_dir = os.path.join(root, f'imagenet{image_size}_labels')\n",
    "conditions_dir = os.path.join(root, f'imagenet{image_size}_conditions')\n",
    "\n",
    "# Setup data:\n",
    "dataset = CustomDataset(features_dir=features_dir, labels_dir=labels_dir, conditions_dir=conditions_dir)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "\n",
    "def main():\n",
    "    idx = 0\n",
    "    x, y, z = None, None, None\n",
    "    for x, y, z in loader:\n",
    "        idx += 1\n",
    "        if idx < 11:\n",
    "            continue\n",
    "        x = x.to(Device)\n",
    "        y = y.to(Device)\n",
    "        z = z.to(Device)\n",
    "\n",
    "        if idx > 0:\n",
    "            break\n",
    "\n",
    "    print(idx, x.shape, y.shape, z.shape)\n",
    "    return x, y, z\n",
    "\n",
    "\n",
    "x, y, z = main()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 torch.Size([1, 1, 3, 256, 256]) torch.Size([1, 1]) torch.Size([1, 256, 256])\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T10:10:15.639585Z",
     "start_time": "2024-05-31T10:10:05.560956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from diffusers import AutoencoderKL\n",
    "from copy import deepcopy\n",
    "from models.DiT import DiT_models\n",
    "from models.control_DiT import control_DiT_models\n",
    "from diffusion import create_diffusion\n",
    "\n",
    "\n",
    "def requires_grad(model, flag=True):\n",
    "    \"\"\"\n",
    "    Set requires_grad flag for all parameters in a model.\n",
    "    \"\"\"\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = flag\n",
    "\n",
    "\n",
    "# Load model:\n",
    "assert image_size % 8 == 0, \"Image size must be divisible by 8 (for the VAE encoder).\"\n",
    "latent_size = image_size // 8\n",
    "model_type = 'DiT-XL/2'\n",
    "dit_model = DiT_models[model_type](\n",
    "    input_size=latent_size,\n",
    "    num_classes=1000,\n",
    ").to(Device)\n",
    "\n",
    "\n",
    "def find_model(model_name):\n",
    "    assert os.path.isfile(model_name), f'Could not find DiT checkpoint at {model_name}'\n",
    "    checkpoint = torch.load(model_name, map_location=lambda storage, loc: storage)\n",
    "    if \"ema\" in checkpoint:  # supports checkpoints from train.py\n",
    "        checkpoint = checkpoint[\"ema\"]\n",
    "    return checkpoint\n",
    "\n",
    "\n",
    "ckpt_path = \"../pretrained_models/DiT-XL-2-256x256.pt\"\n",
    "state_dict = find_model(ckpt_path)\n",
    "dit_model.load_state_dict(state_dict)\n",
    "dit_model.eval()\n",
    "# model.eval()  # important!\n",
    "# Create model:\n",
    "model = control_DiT_models[model_type](\n",
    "    dit_model=dit_model,\n",
    "    input_size=latent_size,\n",
    "    num_classes=1000,\n",
    "    learn_sigma=False,\n",
    ").to(Device)\n",
    "model.train()\n",
    "# # Note that parameter initialization is done within the DiT constructor\n",
    "# model = model.to(Device)\n",
    "# ema = deepcopy(model).to(Device)  # Create an EMA of the model for use after training\n",
    "# requires_grad(ema, False)\n",
    "diffusion = create_diffusion(timestep_respacing=\"\")  # default: 1000 steps, linear noise schedule\n",
    "vae = AutoencoderKL.from_pretrained(f\"../pretrained_models/sd-vae-ft-ema\").to(Device)\n",
    "# Setup optimizer (we used default Adam betas=(0.9, 0.999) and a constant learning rate of 1e-4 in our paper):\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0)\n"
   ],
   "id": "a26e8d5ddffec80",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 40\u001B[0m\n\u001B[1;32m     37\u001B[0m dit_model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m     38\u001B[0m \u001B[38;5;66;03m# model.eval()  # important!\u001B[39;00m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m# Create model:\u001B[39;00m\n\u001B[0;32m---> 40\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mcontrol_DiT_models\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdit_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdit_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlatent_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlearn_sigma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(Device)\n\u001B[1;32m     46\u001B[0m model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;66;03m# # Note that parameter initialization is done within the DiT constructor\u001B[39;00m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;66;03m# model = model.to(Device)\u001B[39;00m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;66;03m# ema = deepcopy(model).to(Device)  # Create an EMA of the model for use after training\u001B[39;00m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;66;03m# requires_grad(ema, False)\u001B[39;00m\n",
      "File \u001B[0;32m~/Projects/control-DiT/models/control_DiT.py:140\u001B[0m, in \u001B[0;36mcontrol_DiT_XL_2\u001B[0;34m(**kwargs)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcontrol_DiT_XL_2\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mControlDiT\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdepth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m28\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1152\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_heads\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/control-DiT/models/control_DiT.py:43\u001B[0m, in \u001B[0;36mControlDiT.__init__\u001B[0;34m(self, dit_model, input_size, patch_size, in_channels, hidden_size, depth, num_heads, mlp_ratio, class_dropout_prob, num_classes, learn_sigma)\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocks \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mModuleList([\n\u001B[1;32m     40\u001B[0m     DiTBlock(hidden_size, num_heads, mlp_ratio\u001B[38;5;241m=\u001B[39mmlp_ratio) \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(depth)\n\u001B[1;32m     41\u001B[0m ])\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinal_layer \u001B[38;5;241m=\u001B[39m FinalLayer(hidden_size, patch_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mout_channels)\n\u001B[0;32m---> 43\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minitialize_weights\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/control-DiT/models/control_DiT.py:53\u001B[0m, in \u001B[0;36mControlDiT.initialize_weights\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     50\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m module\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m             nn\u001B[38;5;241m.\u001B[39minit\u001B[38;5;241m.\u001B[39mconstant_(module\u001B[38;5;241m.\u001B[39mbias, \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m---> 53\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_basic_init\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# Initialize (and freeze) pos_embed by sin-cos embedding:\u001B[39;00m\n\u001B[1;32m     56\u001B[0m pos_embed \u001B[38;5;241m=\u001B[39m get_2d_sincos_pos_embed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpos_embed\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mz_embedder\u001B[38;5;241m.\u001B[39mnum_patches \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.5\u001B[39m))\n",
      "File \u001B[0;32m~/anaconda3/envs/DiT/lib/python3.9/site-packages/torch/nn/modules/module.py:728\u001B[0m, in \u001B[0;36mModule.apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    693\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\u001B[39;00m\n\u001B[1;32m    694\u001B[0m \u001B[38;5;124;03mas well as self. Typical use includes initializing the parameters of a model\u001B[39;00m\n\u001B[1;32m    695\u001B[0m \u001B[38;5;124;03m(see also :ref:`nn-init-doc`).\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    725\u001B[0m \n\u001B[1;32m    726\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    727\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 728\u001B[0m     \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    729\u001B[0m fn(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    730\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/DiT/lib/python3.9/site-packages/torch/nn/modules/module.py:728\u001B[0m, in \u001B[0;36mModule.apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    693\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\u001B[39;00m\n\u001B[1;32m    694\u001B[0m \u001B[38;5;124;03mas well as self. Typical use includes initializing the parameters of a model\u001B[39;00m\n\u001B[1;32m    695\u001B[0m \u001B[38;5;124;03m(see also :ref:`nn-init-doc`).\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    725\u001B[0m \n\u001B[1;32m    726\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    727\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 728\u001B[0m     \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    729\u001B[0m fn(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    730\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "    \u001B[0;31m[... skipping similar frames: Module.apply at line 728 (2 times)]\u001B[0m\n",
      "File \u001B[0;32m~/anaconda3/envs/DiT/lib/python3.9/site-packages/torch/nn/modules/module.py:728\u001B[0m, in \u001B[0;36mModule.apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    693\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\u001B[39;00m\n\u001B[1;32m    694\u001B[0m \u001B[38;5;124;03mas well as self. Typical use includes initializing the parameters of a model\u001B[39;00m\n\u001B[1;32m    695\u001B[0m \u001B[38;5;124;03m(see also :ref:`nn-init-doc`).\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    725\u001B[0m \n\u001B[1;32m    726\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    727\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 728\u001B[0m     \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    729\u001B[0m fn(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    730\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/DiT/lib/python3.9/site-packages/torch/nn/modules/module.py:729\u001B[0m, in \u001B[0;36mModule.apply\u001B[0;34m(self, fn)\u001B[0m\n\u001B[1;32m    727\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m    728\u001B[0m     module\u001B[38;5;241m.\u001B[39mapply(fn)\n\u001B[0;32m--> 729\u001B[0m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    730\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/Projects/control-DiT/models/control_DiT.py:49\u001B[0m, in \u001B[0;36mControlDiT.initialize_weights.<locals>._basic_init\u001B[0;34m(module)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_basic_init\u001B[39m(module):\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(module, nn\u001B[38;5;241m.\u001B[39mLinear):\n\u001B[0;32m---> 49\u001B[0m         \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mxavier_uniform_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m module\u001B[38;5;241m.\u001B[39mbias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m             nn\u001B[38;5;241m.\u001B[39minit\u001B[38;5;241m.\u001B[39mconstant_(module\u001B[38;5;241m.\u001B[39mbias, \u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/DiT/lib/python3.9/site-packages/torch/nn/init.py:327\u001B[0m, in \u001B[0;36mxavier_uniform_\u001B[0;34m(tensor, gain)\u001B[0m\n\u001B[1;32m    324\u001B[0m std \u001B[38;5;241m=\u001B[39m gain \u001B[38;5;241m*\u001B[39m math\u001B[38;5;241m.\u001B[39msqrt(\u001B[38;5;241m2.0\u001B[39m \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mfloat\u001B[39m(fan_in \u001B[38;5;241m+\u001B[39m fan_out))\n\u001B[1;32m    325\u001B[0m a \u001B[38;5;241m=\u001B[39m math\u001B[38;5;241m.\u001B[39msqrt(\u001B[38;5;241m3.0\u001B[39m) \u001B[38;5;241m*\u001B[39m std  \u001B[38;5;66;03m# Calculate uniform bounds from standard deviation\u001B[39;00m\n\u001B[0;32m--> 327\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_no_grad_uniform_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/DiT/lib/python3.9/site-packages/torch/nn/init.py:14\u001B[0m, in \u001B[0;36m_no_grad_uniform_\u001B[0;34m(tensor, a, b)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_no_grad_uniform_\u001B[39m(tensor, a, b):\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 14\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtensor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muniform_\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from collections import OrderedDict\n",
    "# from accelerate import Accelerator\n",
    "#\n",
    "# accelerator = Accelerator()\n",
    "# @torch.no_grad()\n",
    "# def update_ema(ema_model, model, decay=0.9999):\n",
    "#     \"\"\"\n",
    "#     Step the EMA model towards the current model.\n",
    "#     \"\"\"\n",
    "#     ema_params = OrderedDict(ema_model.named_parameters())\n",
    "#     model_params = OrderedDict(model.named_parameters())\n",
    "#\n",
    "#     for name, param in model_params.items():\n",
    "#         name = name.replace(\"module.\", \"\")\n",
    "#         # TODO: Consider applying only to params that require_grad to avoid small numerical changes of pos_embed\n",
    "#         ema_params[name].mul_(decay).add_(param.data, alpha=1 - decay)\n",
    "\n",
    "#\n",
    "# # Prepare models for training:\n",
    "# update_ema(ema, model, decay=0)  # Ensure EMA is initialized with synced weights\n",
    "# model.train()  # important! This enables embedding dropout for classifier-free guidance\n",
    "# ema.eval()  # EMA model should always be in eval mode\n",
    "# model, opt, loader = accelerator.prepare(model, opt, loader)\n",
    "\n",
    "x = x.squeeze(dim=1)\n",
    "b = torch.zeros(x.shape)\n",
    "z = z.expand_as(b)\n",
    "print(z[0][0] == z[0][1])\n",
    "# z = b\n",
    "with torch.no_grad():\n",
    "            # Map input images to latent space + normalize latents:\n",
    "    x = vae.encode(x).latent_dist.sample().mul_(0.18215)\n",
    "    z = vae.encode(z).latent_dist.sample().mul_(0.18215)\n",
    "y = y.squeeze(dim=1)\n",
    "z = z.squeeze(dim=1)\n",
    "t = torch.randint(0, diffusion.num_timesteps, (z.shape[0],), device=Device)\n",
    "nx = model.forward(x, z, y, t)\n",
    "print(nx.shape)\n"
   ],
   "id": "272373334ac786a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "print(nx.shape, nx.max())\n",
    "sample = vae.decode(nx / 0.18215).sample\n",
    "print(sample.shape)\n",
    "# Save and display images:\n",
    "save_image(sample, \"sample.png\", nrow=4, normalize=True, value_range=(0, 255))\n"
   ],
   "id": "23158849dfa1ddbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "2c437a6aadfaa9b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1b0f445efb54d5b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "393dbedb8770429a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f2423dcae2c0f1ae",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
